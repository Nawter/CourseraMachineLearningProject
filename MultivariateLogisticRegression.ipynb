{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Multivariate Logistic Regression </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing the data </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by loading the data set. Unlike the previous examples, our data file is in a format native to MATLAB and not automatically recognizable by pandas, so to load it in Python we need to use a SciPy utility (remember the data files are available at the link at the top of the post)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " '__globals__': [],\n",
       " '__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ..., \n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.io import loadmat  \n",
    "%matplotlib inline\n",
    "\n",
    "data = loadmat('data/ex3data1.mat')  \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1), (400, 5000), (1, 5000))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape, data['y'].shape, data['X'].T.shape, data['y'].T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sigmoid Function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):  \n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cost Function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y, learningRate):  \n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    reg = (learningRate / 2 * len(X)) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "    return np.sum(first - second) / (len(X)) + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gradient Descent Function </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\theta_0 := \\theta_0 * \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^i)-y^i) (x_0^i) \\\\\n",
    "\\theta_j := \\theta_j * \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^i)-y^i) (x_j^i) + \\frac\\lambda {m} \\theta_j\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loop Form </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_with_loop(theta, X, y, learningRate):  \n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "\n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "\n",
    "        if (i == 0):\n",
    "            grad[i] = np.sum(term) / len(X)\n",
    "        else:\n",
    "            grad[i] = (np.sum(term) / len(X)) + ((learningRate / len(X)) * theta[:,i])\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Vectorized Form </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, learningRate):  \n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "\n",
    "    grad = ((X.T * error) / len(X)).T + ((learningRate / len(X)) * theta)\n",
    "\n",
    "    # intercept gradient is not regularized\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
    "\n",
    "    return np.array(grad).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that we're converting the data structures to NumPy matrices (which I've used for the most part throughout these exercises). This is done in an attempt to make the code look more similar to Octave than it would using arrays because matrices automatically follow matrix operation rules vs. element-wise operations, which is the default for arrays. There is some debate in the community over whether or not the matrix class should be used at all, but it's there so we're using it in these examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What it's means matrix operation rules vs element-wise operations, make reserach on this area???</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> One-vs-all Classification </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def one_vs_all(X, y, num_labels, learning_rate):  \n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "\n",
    "    # k X (n + 1) array for the parameters of each of the k classifiers\n",
    "    all_theta = np.zeros((num_labels, params + 1))\n",
    "\n",
    "    # insert a column of ones at the beginning for the intercept term\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "    # labels are 1-indexed instead of 0-indexed\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(params + 1)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        y_i = np.reshape(y_i, (rows, 1))\n",
    "\n",
    "        # minimize the objective function\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, learning_rate), method='TNC', jac=gradient)\n",
    "        all_theta[i-1,:] = fmin.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 1), (401,), (10, 401))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = data['X'].shape[0]  \n",
    "params = data['X'].shape[1]\n",
    "\n",
    "all_theta = np.zeros((10, params + 1))\n",
    "\n",
    "X = np.insert(data['X'], 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "theta = np.zeros(params + 1)\n",
    "\n",
    "y_0 = np.array([1 if label == 0 else 0 for label in data['y']])  \n",
    "y_0 = np.reshape(y_0, (rows, 1))\n",
    "\n",
    "X.shape, y_0.shape, theta.shape, all_theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.70247932e-05,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -2.24803601e-10,   2.31962906e-11,   0.00000000e+00],\n",
       "       [ -8.96250751e-05,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          7.26120862e-09,  -6.19965329e-10,   0.00000000e+00],\n",
       "       [ -8.39553375e-05,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -7.61695635e-10,   4.64917650e-11,   0.00000000e+00],\n",
       "       ..., \n",
       "       [ -7.00832719e-05,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -6.92009371e-10,   4.29241679e-11,   0.00000000e+00],\n",
       "       [ -7.65188090e-05,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -8.09503513e-10,   5.31058851e-11,   0.00000000e+00],\n",
       "       [ -6.63412491e-05,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -3.49765984e-09,   1.13668571e-10,   0.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_theta = one_vs_all(data['X'], data['y'], 10, 1)  \n",
    "all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> One-vs-all Prediction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(X, all_theta):  \n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    # same as before, insert ones to match the shape\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "    # convert to matrices\n",
    "    X = np.matrix(X)\n",
    "    all_theta = np.matrix(all_theta)\n",
    "\n",
    "    # compute the class probability for each class on each training instance\n",
    "    h = sigmoid(X * all_theta.T)\n",
    "\n",
    "    # create array of the index with the maximum probability\n",
    "    h_argmax = np.argmax(h, axis=1)\n",
    "\n",
    "    # because our array was zero-indexed we need to add one for the true label prediction\n",
    "    h_argmax = h_argmax + 1\n",
    "\n",
    "    return h_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.6\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_all(data['X'], all_theta)  \n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, data['y'])]  \n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))  \n",
    "print (accuracy * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
